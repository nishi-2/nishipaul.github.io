{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6732769c-a532-4814-a5ff-6dee4c657eeb",
   "metadata": {},
   "source": [
    "## Building a RAG Pipeline with BBC News Data\n",
    "\n",
    "Have you ever wondered how Large Language Models (LLMs) can stay updated with recent events even after their training cut-off? That’s where **Retrieval-Augmented Generation (RAG)** steps in! In this project, we’ll take on the challenge of building a RAG pipeline using a dataset of news articles from **BBC News**.\n",
    "\n",
    "The main objective? To empower our LLM to retrieve the most relevant news details from the dataset and weave that information into its responses. The model we’re working with is **llama-3.1 from Ollama**. While the model is impressive, it doesn't have information on latest data and that’s exactly the gap we’ll fill with our RAG system.\n",
    "\n",
    "Here’s what this blog involves:\n",
    "\n",
    "* **Query & Retrieval:** Implement a function that fetches relevant news snippets based on the user’s query.\n",
    "* **Data Formatting:** Organize the retrieved information so that it’s clean and contextually useful.\n",
    "* **Prompt Engineering:** Combine the original query and the retrieved data into a well-crafted prompt, then feed it into the LLM for a richer, more informed response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54dccb0-3f5b-4944-b441-7c315707020f",
   "metadata": {},
   "source": [
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50c93d1-fe8d-4a3c-85a3-97e2b8c1bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from dateutil import parser\n",
    "import joblib\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ed4be-acd7-4e4e-bac9-d06b51aec679",
   "metadata": {},
   "source": [
    "#### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bd19fb-46bb-4f9a-a471-04f29e594d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>venue</th>\n",
       "      <th>url</th>\n",
       "      <th>published_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3dc5caa18f9a16d7edcc09f8d5c2bb4</td>\n",
       "      <td>Harvey Weinstein's 2020 rape conviction overtu...</td>\n",
       "      <td>Victims group describes the New York appeal co...</td>\n",
       "      <td>BBC</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-us-canada-688...</td>\n",
       "      <td>2024-04-25 18:24:04+00</td>\n",
       "      <td>2024-04-26 20:03:00.628113+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297b7152cd95e80dd200a8e1997e10d9</td>\n",
       "      <td>Police and activists clash on Atlanta campus a...</td>\n",
       "      <td>Meanwhile, hundreds of students march in Washi...</td>\n",
       "      <td>BBC</td>\n",
       "      <td>https://www.bbc.co.uk/news/live/world-us-canad...</td>\n",
       "      <td>2024-04-25 13:40:25+00</td>\n",
       "      <td>2024-04-26 20:03:00.654819+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170bd18d1635c44b9339bdbaf1e62123</td>\n",
       "      <td>Haiti PM resigns as transitional council sworn in</td>\n",
       "      <td>The council will try to restore order and form...</td>\n",
       "      <td>BBC</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-latin-america...</td>\n",
       "      <td>2024-04-25 18:11:02+00</td>\n",
       "      <td>2024-04-26 20:03:00.663393+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               guid  \\\n",
       "0  e3dc5caa18f9a16d7edcc09f8d5c2bb4   \n",
       "1  297b7152cd95e80dd200a8e1997e10d9   \n",
       "2  170bd18d1635c44b9339bdbaf1e62123   \n",
       "\n",
       "                                               title  \\\n",
       "0  Harvey Weinstein's 2020 rape conviction overtu...   \n",
       "1  Police and activists clash on Atlanta campus a...   \n",
       "2  Haiti PM resigns as transitional council sworn in   \n",
       "\n",
       "                                         description venue  \\\n",
       "0  Victims group describes the New York appeal co...   BBC   \n",
       "1  Meanwhile, hundreds of students march in Washi...   BBC   \n",
       "2  The council will try to restore order and form...   BBC   \n",
       "\n",
       "                                                 url            published_at  \\\n",
       "0  https://www.bbc.co.uk/news/world-us-canada-688...  2024-04-25 18:24:04+00   \n",
       "1  https://www.bbc.co.uk/news/live/world-us-canad...  2024-04-25 13:40:25+00   \n",
       "2  https://www.bbc.co.uk/news/world-latin-america...  2024-04-25 18:11:02+00   \n",
       "\n",
       "                      updated_at  \n",
       "0  2024-04-26 20:03:00.628113+00  \n",
       "1  2024-04-26 20:03:00.654819+00  \n",
       "2  2024-04-26 20:03:00.663393+00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWS_DATA = pd.read_csv(\"news_data_dedup.csv\")\n",
    "NEWS_DATA.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1ab0b-0590-47ca-a118-7cb3044df3c4",
   "metadata": {},
   "source": [
    "**Defining an utility function for reading the dataset from the given path and then converting the pandas dataframe into a list of dictionaries of records.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e724a418-bf16-4997-b1bc-0debe4740715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date_string):\n",
    "    date_object = parser.parse(date_string)  #parsing string into datetime object\n",
    "    formatted_date = date_object.strftime(\"%Y-%m-%d\")\n",
    "    return formatted_date\n",
    "\n",
    "\n",
    "def read_dataframe(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    df['published_at'] = df['published_at'].apply(format_date)\n",
    "    df['updated_at'] = df['updated_at'].apply(format_date)\n",
    "\n",
    "    df= df.to_dict(orient='records') # Convert the DataFrame to dictionary after formatting\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8b8b3d-c4f9-449d-83be-723d1e760a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'guid': 'e3dc5caa18f9a16d7edcc09f8d5c2bb4',\n",
       "  'title': \"Harvey Weinstein's 2020 rape conviction overturned\",\n",
       "  'description': 'Victims group describes the New York appeal court\\'s decision to retry Hollywood mogul as \"profoundly unjust\".',\n",
       "  'venue': 'BBC',\n",
       "  'url': 'https://www.bbc.co.uk/news/world-us-canada-68899382',\n",
       "  'published_at': '2024-04-25',\n",
       "  'updated_at': '2024-04-26'},\n",
       " {'guid': '297b7152cd95e80dd200a8e1997e10d9',\n",
       "  'title': 'Police and activists clash on Atlanta campus amid Gaza protests',\n",
       "  'description': 'Meanwhile, hundreds of students march in Washington DC, and congresswoman Ilhan Omar joins protesters at a New York campus.',\n",
       "  'venue': 'BBC',\n",
       "  'url': 'https://www.bbc.co.uk/news/live/world-us-canada-68898923',\n",
       "  'published_at': '2024-04-25',\n",
       "  'updated_at': '2024-04-26'},\n",
       " {'guid': '170bd18d1635c44b9339bdbaf1e62123',\n",
       "  'title': 'Haiti PM resigns as transitional council sworn in',\n",
       "  'description': 'The council will try to restore order and form a new government in the nation gripped by gang violence.',\n",
       "  'venue': 'BBC',\n",
       "  'url': 'https://www.bbc.co.uk/news/world-latin-america-68896323',\n",
       "  'published_at': '2024-04-25',\n",
       "  'updated_at': '2024-04-26'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWS_DATA = read_dataframe(\"news_data_dedup.csv\")\n",
    "NEWS_DATA[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a1d2a-0ec5-4fc3-9db7-55e2576104b4",
   "metadata": {},
   "source": [
    "#### Initiating the embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d41ab7-336a-49cf-b459-e27a53ed3e7b",
   "metadata": {},
   "source": [
    "In order to perform the retrieval, we need to embed the data and query both. To generate embeddings for text, we use the SentenceTransformer library with the BAAI/bge-base-en-v1.5 model. This model is a powerful, pre-trained transformer designed for producing high-quality dense embeddings, suitable for semantic search, retrieval-augmented generation (RAG), and other NLP tasks. By initializing the model using SentenceTransformer(embedding_model_name), we can easily convert textual data into vector representations that capture semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66fcd252-ddce-4fdd-b55e-16af2f15a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "embed_model = SentenceTransformer(embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81844c6a-379a-4f16-a5b0-a241e62416f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526df0b1-a5a2-4fee-9dce-d04f6c8c078a",
   "metadata": {},
   "source": [
    "News dataset was already embedded using the same embedding model and was saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4adde6db-377a-4a3c-abbf-59453d182436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the embeddings of the dataset\n",
    "EMBEDDINGS = joblib.load(\"embeddings.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417afb6-6fbb-442b-8448-a6cac3d78d53",
   "metadata": {},
   "source": [
    "**The below process is followed for generating and saving embeddings for the dataset loaded**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec4bc1-37af-4d1b-9fc4-ee63c38ba62b",
   "metadata": {},
   "source": [
    "The below function **concatenates multiple fields from each record in a dataset into a single text string**. It loops through each data entry, retrieves the specified fields (if they exist, otherwise uses an empty string), appends their values separated by spaces, trims extra whitespace, and stores the combined text in a list. Finally, it returns this list of concatenated strings. This is used when you need to embed the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cf4040b-1825-48ee-a9dc-2ad62d802a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_fields(dataset, fields):\n",
    "    concatenated_data = []   # list where texts will be stored\n",
    "\n",
    "    for data in dataset:\n",
    "        text = ''\n",
    "        for field in fields:\n",
    "            context = data.get(field, '') # get the desired filed if found else empty string is used\n",
    "            if context:\n",
    "                text += f\"{context} \"  # add context to text if context is available\n",
    "\n",
    "        text = text.strip() # strip whitespace from text\n",
    "        concatenated_data.append(text)\n",
    "\n",
    "    return concatenated_data\n",
    "\n",
    "\n",
    "def generate_and_save_embeddings(dataset, fields, model_name=\"BAAI/bge-base-en-v1.5\", output_path='embeddings.joblib'):\n",
    "    # Concatenate fields into text\n",
    "    concatenated_texts = concatenate_fields(dataset, fields)\n",
    "\n",
    "    # Load the embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Generate embeddings\n",
    "    embeddings = model.encode(concatenated_texts, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "    # Save embeddings using joblib\n",
    "    joblib.dump(embeddings, output_path)\n",
    "    print(f\"Embeddings saved to {output_path}\")\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# dataset = This is the list of dictionaries that we created above\n",
    "# fields = The column names\n",
    "# embeddings = generate_and_save_embeddings(dataset, fields, output_path='news_embeddings.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e2a24-b4bf-4f80-9f04-74c0d45d50ee",
   "metadata": {},
   "source": [
    "#### Defining model calling function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69024fb4-ccc4-47d4-9cd5-0457421725a6",
   "metadata": {},
   "source": [
    "Now that we have the dataset in dictionary format and the embeddings ready, we can define the LLM model calling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44720332-0af5-4380-a458-df66490e259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For printing\n",
    "def pprint(*args, **kwargs):\n",
    "    print(json.dumps(*args, indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca0345-6ad6-4e4b-9655-18afdcd2e584",
   "metadata": {},
   "source": [
    "**Initiating the model call with a single prompt input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98f8d1d6-9144-4703-8a22-7b67747fcc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_single_input(\n",
    "                            prompt: str,\n",
    "                            role: str = 'user',\n",
    "                            top_p: float = 0.1,\n",
    "                            temperature: float = 0.1,\n",
    "                            max_tokens: int = 500,\n",
    "                            model: str = \"llama3.1:8b\",\n",
    "                            **kwargs\n",
    "                                ):\n",
    "\n",
    "\n",
    "    llm = ChatOllama(\n",
    "        model = model,\n",
    "        temperature = temperature,\n",
    "        top_p= top_p,\n",
    "        frequency_penalty = 0.5,\n",
    "        presence_penalty = 0.3,\n",
    "        max_tokens = max_tokens\n",
    "        )\n",
    "\n",
    "    \n",
    "    role_map = {\"user\" : HumanMessage,\n",
    "                \"system\" : SystemMessage,\n",
    "                \"assistant\" : AIMessage}\n",
    "\n",
    "\n",
    "    content_passed = prompt\n",
    "    role = role_map[role]\n",
    "    messages = [role(content=content_passed)]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    response_role = \"assistant\" if response.type == \"ai\" else response.type\n",
    "    response_type = {'Role':response_role}\n",
    "\n",
    "    # Convert to dictionary\n",
    "    json_dict = response.model_dump()\n",
    "    json_dict.update(response_type)  # Adding response type with the response dictionary\n",
    "\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408d8e1-48fa-47a9-9d40-dbf2b43065e9",
   "metadata": {},
   "source": [
    "#### Building the retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b18ef-b516-4e15-aaa1-52d2693626e8",
   "metadata": {},
   "source": [
    "We have the dataset in dictionary format, embeddings of the dataset, and the LLM calling function defined. Now we need to provide the LLM with the required set of data as per the user query, for which we need to define the retriever method. The function **`query_news`** takes a list of indices as input and retrieves all documents from a dataset that correspond to those indices. Essentially, it acts like a lookup function: for each index in the list, it fetches the associated document (such as a news article) and returns the collection of these documents. This is commonly used when you already know which specific records you need, often after a search or filtering operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31c3af7e-2886-4287-a2ac-f90ba511413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_news(indices: list) -> list:\n",
    "    output = [NEWS_DATA[index] for index in indices]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e191fe-bbef-471d-97b5-d3797ef469cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"guid\": \"733f744b006fb13033d264efcaf8edad\",\n",
      "    \"title\": \"Prosecutors ask for halt to case against Spain PM's wife\",\n",
      "    \"description\": \"Pedro S\\u00e1nchez is deciding whether to resign after a case against his wife by an anti-corruption group.\",\n",
      "    \"venue\": \"BBC\",\n",
      "    \"url\": \"https://www.bbc.co.uk/news/world-europe-68895727\",\n",
      "    \"published_at\": \"2024-04-25\",\n",
      "    \"updated_at\": \"2024-04-26\"\n",
      "  },\n",
      "  {\n",
      "    \"guid\": \"d2c3ff79d4e068911d05416ca061cd51\",\n",
      "    \"title\": \"Ukraine uses longer-range US missiles for first time\",\n",
      "    \"description\": \"Missiles secretly delivered this month have been used to strike Russian targets in Crimea, US media say.\",\n",
      "    \"venue\": \"BBC\",\n",
      "    \"url\": \"https://www.bbc.co.uk/news/world-europe-68893196\",\n",
      "    \"published_at\": \"2024-04-25\",\n",
      "    \"updated_at\": \"2024-04-26\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Let's say you need to see the values at index 4 and 10 in the news dataset\n",
    "indices = [4,10]\n",
    "pprint(query_news(indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a7439-8443-464a-acc7-0f190c02a9de",
   "metadata": {},
   "source": [
    "**The `retrieve` function is a crucial component of the RAG system. It is designed to identify and return the most relevant documents from a given corpus based on a provided query.**\n",
    "\n",
    "This function takes two input parameters: `query` and `top_k`. The `query` parameter is a string representing the search query for which the system needs to find the most relevant documents. The `top_k` parameter is an integer that specifies how many of the top similar documents should be retrieved. Upon execution, the function processes the query and compares it against the corpus to determine similarity scores, then returns a list of indices corresponding to the top `k` most relevant documents. These indices serve as references to the original documents, which can later be used for generating precise and contextually relevant responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53e269a8-4fd2-4778-87aa-9feea079cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_k = 5): # Default value for document to return is 5\n",
    "\n",
    "    # Convert the input query into a numerical embedding vector using the pre-trained embedding model.\n",
    "    query_embedding = embed_model.encode(query)\n",
    "\n",
    "    # Compute the cosine similarity between the query embedding (reshaped into a 2D array) and all stored embeddings.\n",
    "    # This returns an array of similarity scores for each stored document.\n",
    "    similarity_score = cosine_similarity(query_embedding.reshape(1,-1), EMBEDDINGS)[0]\n",
    "\n",
    "    # Sort the indices of documents in descending order of similarity (highest similarity first).\n",
    "    # Negative sign (-similarity_score) ensures sorting in descending order.\n",
    "    similarity_indices = np.argsort(-similarity_score)\n",
    "\n",
    "    # Select the first 'top_k' indices from the sorted list, which correspond to the most similar documents.\n",
    "    top_k_indices = similarity_indices[:top_k]\n",
    "\n",
    "    return top_k_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1753e816-9913-41c6-b793-60a96b250672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350]\n"
     ]
    }
   ],
   "source": [
    "query = \"Concerts in North America\"\n",
    "indices = retrieve(query, top_k = 1) # Passing the query to get the top index similar to the query\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cafed2f9-b8db-4fce-833f-2e2f1e0f65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"guid\": \"927257674585bb6ef669cf2c2f409fa7\",\n",
      "    \"title\": \"\\u2018The working class can\\u2019t afford it\\u2019: the shocking truth about the money bands make on tour\",\n",
      "    \"description\": \"As Taylor Swift tops $1bn in tour revenue, musicians playing smaller venues are facing pitiful fees and frequent losses. Should the state step in to save our live music scene?When you see a band playing to thousands of fans in a sun-drenched festival field, signing a record deal with a major label or playing endlessly from the airwaves, it\\u2019s easy to conjure an image of success that comes with some serious cash to boot \\u2013 particularly when Taylor Swift has broken $1bn in revenue for her current Eras tour. But looks can be deceiving. \\u201cI don\\u2019t blame the public for seeing a band playing to 2,000 people and thinking they\\u2019re minted,\\u201d says artist manager Dan Potts. \\u201cBut the reality is quite different.\\u201dPost-Covid there has been significant focus on grassroots music venues as they struggle to stay open. There\\u2019s been less focus on the actual ability of artists to tour these venues. David Martin, chief executive officer of the Featured Artists Coalition (FAC), says we\\u2019re in a \\u201ccost-of-touring crisis\\u201d. Pretty much every cost attached to touring \\u2013 van hire, crew, travel, accommodation, food and drink \\u2013 has gone up, while fees and audiences often have not. \\u201c[Playing] live is becoming financially unsustainable for many artists,\\u201d he says. \\u201cArtists are seeing [playing] live as a loss leader now. That\\u2019s if they can even afford to make it work in the first place.\\u201d Continue reading...\",\n",
      "    \"venue\": \"The Guardian\",\n",
      "    \"url\": \"https://www.theguardian.com/music/2024/apr/25/shocking-truth-money-bands-make-on-tour-taylor-swift\",\n",
      "    \"published_at\": \"2024-04-25\",\n",
      "    \"updated_at\": \"2024-04-26\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "retrieved_documents = query_news(indices) # Passing the top index to get the data from news dataset at that index\n",
    "pprint(retrieved_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ce3593-d523-4022-b3db-b523b64a39ad",
   "metadata": {},
   "source": [
    "**We will encapsulate the above logic into a function called `get_relevant_data`. This function accepts a query and a `top_k` parameter, then retrieves and returns the top `top_k` most relevant documents.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c20ff775-b30b-4898-893f-f6d38887024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_data(query: str, top_k: int = 5) -> list[dict]:\n",
    "    relevant_indices = retrieve(query, top_k)  # Getting the top_k similar indices with the prompt via similarity search\n",
    "\n",
    "    # We are using the embeddings to fetch the most similar data and are not passing those embeddings to the LLM\n",
    "    relevant_data = query_news(relevant_indices)  # Passing the retrieved indices into the news dataset to get relevant data from news dataset\n",
    "    return relevant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd9221f-075e-4c6d-8b2a-d947d6c7adea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"guid\": \"3ca548fe82c3fcae2c4c0c635d03eb2e\",\n",
      "    \"title\": \"Large tornado seen touching down in Nebraska\",\n",
      "    \"description\": \"Severe and powerful storms have moved across several US states, leaving many experiencing power shortages.\",\n",
      "    \"venue\": \"BBC\",\n",
      "    \"url\": \"https://www.bbc.co.uk/news/world-us-canada-68860070\",\n",
      "    \"published_at\": \"2024-04-26\",\n",
      "    \"updated_at\": \"2024-04-28\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "query = \"Greatest storms in the US\"\n",
    "relevant_data = get_relevant_data(query, top_k = 1)\n",
    "pprint(relevant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a95031-1ecf-453f-a74c-302528b5f4c0",
   "metadata": {},
   "source": [
    "Now that we have the essential retrieved data, we need to create a function that takes a list of documents as input and produces a well-structured string containing the details of each document. The output includes the following fields for each news item:\n",
    "\n",
    "* **News Title**\n",
    "* **News Description**\n",
    "* **News Published Date**\n",
    "* **News URL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53ef3015-4a46-4e63-adf0-d724e4a3d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_relevant_data(relevant_data: list[dict]) -> str:\n",
    "    formatted_documents = []\n",
    "    \n",
    "    for document in relevant_data:\n",
    "        # Formats each document into a structured layout string. Each document is in one different line.\n",
    "        formatted_document = f\"\"\"\n",
    "        Title:{document['title']}, Description:{document['description']}, Published At: {document['published_at']},\\n URL: {document['url']} \n",
    "        \"\"\"\n",
    "\n",
    "        formatted_documents.append(formatted_document)\n",
    "\n",
    "    return \"\\n\".join(formatted_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e65ffd3f-b31a-422c-b390-2e674ea29196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Title:Prosecutors ask for halt to case against Spain PM's wife, Description:Pedro Sánchez is deciding whether to resign after a case against his wife by an anti-corruption group., Published At: 2024-04-25,\n",
      " URL: https://www.bbc.co.uk/news/world-europe-68895727 \n",
      "        \n",
      "\n",
      "        Title:WATCH: Would you pay a tourist fee to enter Venice?, Description:From Thursday visitors making a trip to the famous city at peak times will be charged a trial entrance fee., Published At: 2024-04-25,\n",
      " URL: https://www.bbc.co.uk/news/world-europe-68898441 \n",
      "        \n",
      "\n",
      "        Title:Supreme Court divided on whether Trump has immunity, Description:The justices discussed immunity, coups, pardons, Operation Mongoose - and the future of democracy., Published At: 2024-04-25,\n",
      " URL: https://www.bbc.co.uk/news/world-us-canada-68901817 \n",
      "        \n",
      "\n",
      "        Title:More than 150 killed as heavy rains pound Tanzania, Description:The prime minister warns that El Niño-triggered heavy rains are likely to continue into May., Published At: 2024-04-25,\n",
      " URL: https://www.bbc.co.uk/news/world-africa-68896454 \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Checking how the format_relevant_data looks like\n",
    "example_data = NEWS_DATA[4:8]\n",
    "print(format_relevant_data(example_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da0de3-4f3c-4dde-9a5c-cd73aebd95af",
   "metadata": {},
   "source": [
    "#### Generating prompt and calling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b051e95-ade0-46e8-a138-a43553fcafb1",
   "metadata": {},
   "source": [
    "The next function, **generate\\_final\\_prompt**, is responsible for creating the complete prompt by seamlessly integrating the user’s query with the retrieved and formatted relevant data. This function ensures that the final prompt includes all essential context for the model to generate an accurate and informative response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a8345c8-6bde-455f-a08f-2ea0cc102837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_prompt(query, top_k=5, use_rag=True, prompt=None):\n",
    "\n",
    "    # If RAG is not being used, format the prompt with just the query or return the query directly\n",
    "    if not use_rag:\n",
    "        return query\n",
    "\n",
    "    # Getting the relevant data as per the query passed\n",
    "    relevant_data = get_relevant_data(query, top_k = top_k)\n",
    "\n",
    "    # Formatting the relevant data fetched\n",
    "    retrieve_data_formatted = format_relevant_data(relevant_data)\n",
    "\n",
    "    # If no prompt is given then use this default\n",
    "    if prompt is None:\n",
    "        prompt = (\n",
    "            f\"Answer the user query below. There will be provided additional information for you to compose your answer. \"\n",
    "            f\"The relevant information provided is from 2024 and it should be added as your overall knowledge to answer the query, \"\n",
    "            f\"you should not rely only on this information to answer the query, but add it to your overall knowledge.\"\n",
    "            f\"Query: {query}\\n\"\n",
    "            f\"2024 News: {retrieve_data_formatted}\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = prompt.format(query = query, documents = retrieve_data_formatted)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e858fbc-17fd-4afd-8316-286de943f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the user query below. There will be provided additional information for you to compose your answer. The relevant information provided is from 2024 and it should be added as your overall knowledge to answer the query, you should not rely only on this information to answer the query, but add it to your overall knowledge.Query: Tell me about the US GDP in the past 3 years.\n",
      "2024 News: \n",
      "        Title:America's Economy Is No. 1. That Means Trouble, Description:If you want a single number to capture America’s economic stature, here it is: This year, the U.S. will account for 26.3% of the global gross domestic product, the highest in almost two decades. That’s based on the latest projections from the International Monetary Fund. According to the IMF, Europe’s share of world GDP has dropped 1.4 percentage points since 2018, and Japan’s by 2.1 points. The U.S. share, by contrast, is up 2.3 points., Published At: 2024-04-26,\n",
      " URL: https://www.wsj.com/articles/americas-economy-is-no-1-that-means-trouble-d008e4bd \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(generate_final_prompt(query = \"Tell me about the US GDP in the past 3 years.\", top_k = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5f590-cecd-4d81-8a34-f9fa2a0b2e0a",
   "metadata": {},
   "source": [
    "**Calling the model with the prompt**\n",
    "\n",
    "The **LLM Call** step involves integrating the previously defined function to generate the final prompt and pass it to a language model for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d7141da-e3cd-4253-8064-133547171f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(query, top_k=5, use_rag=True, prompt=None):\n",
    "    prompt = generate_final_prompt(query, top_k, use_rag, prompt)  # Getting the required prompt as per query\n",
    "    generate_response = generate_with_single_input(prompt)  # Calling the model with the prompt having the required data from dataset\n",
    "    generated_message = generate_response['content']\n",
    "    return generated_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5323f6-46c6-4e28-9144-b64c5bee6eff",
   "metadata": {},
   "source": [
    "**Calling the model using RAG Approach. Observe the output returned using RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e272e914-3056-4a28-ac9a-d467542ff834",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me about the US GDP in the past 3 years.\"\n",
    "result_with_rag = llm_call(query, use_rag=True, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "273c2859-52c2-4cac-9145-bb95fff1979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided news articles from 2024, here's an overview of the US GDP in the past three years:\n",
      "\n",
      "1. **2022**: Unfortunately, there is no specific information about the US GDP for 2022 in the provided articles. However, I can provide general knowledge that the US economy has been growing steadily over the past few years.\n",
      "2. **2023**: The exact numbers are not mentioned in the articles, but it's reported that the US will account for 26.3% of the global gross domestic product (GDP) in 2024, which is the highest in almost two decades. This suggests a strong growth trend in the US economy.\n",
      "3. **2024**: According to the International Monetary Fund (IMF), the US share of world GDP has increased by 2.3 percentage points since 2018.\n",
      "\n",
      "It's worth noting that while the US GDP and Dow Jones Industrial Average have been rising, there are concerns about whether these metrics accurately reflect American well-being. The articles mention solid growth, big deficits, and a strong dollar, which stir memories of past economic crises.\n",
      "\n",
      "To provide more context, I can add general knowledge about the US economy in recent years:\n",
      "\n",
      "* In 2022, the US GDP grew at an annual rate of around 2-3%, driven by consumer spending and business investment.\n",
      "* The COVID-19 pandemic had a significant impact on the global economy, including the US, but the country's strong recovery was fueled by government stimulus packages and monetary policy support.\n",
      "* In recent years, there have been concerns about rising inflation, trade tensions, and the impact of technological changes on employment.\n",
      "\n",
      "Please let me know if you'd like more information or specific data on the US GDP for these years.\n"
     ]
    }
   ],
   "source": [
    "print(result_with_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c0f71-bdd6-4fb6-9d33-a3e76e8da860",
   "metadata": {},
   "source": [
    "**Calling the model without using RAG Approach. Observe the output returned is quiet vague and is not as per data we have**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dcd3feb-261a-475f-bf5a-ddef6f419bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an overview of the US Gross Domestic Product (GDP) for the past three years, based on data from the Bureau of Economic Analysis (BEA):\n",
      "\n",
      "**2020:**\n",
      "\n",
      "* The COVID-19 pandemic had a significant impact on the US economy.\n",
      "* GDP contracted by 3.4% in 2020, marking the first recession since 2009.\n",
      "* The decline was largely due to lockdowns and social distancing measures that reduced consumer spending and business activity.\n",
      "* However, government stimulus packages and monetary policy support helped mitigate the downturn.\n",
      "\n",
      "**2021:**\n",
      "\n",
      "* After a slow start, the US economy rebounded strongly in 2021.\n",
      "* GDP grew by 5.7% in 2021, driven by:\n",
      "\t+ A rapid recovery in consumer spending, as lockdowns were lifted and vaccination rates improved.\n",
      "\t+ Strong growth in business investment, particularly in technology and healthcare sectors.\n",
      "\t+ Government stimulus packages continued to support the economy.\n",
      "\n",
      "**2022:**\n",
      "\n",
      "* The US economy experienced a slowdown in 2022, due to:\n",
      "\t+ Rising inflation (4.7% annual rate) and interest rates, which reduced consumer spending power.\n",
      "\t+ Supply chain disruptions and labor shortages, particularly in industries like manufacturing and logistics.\n",
      "\t+ A decline in government stimulus support.\n",
      "* GDP growth slowed to 1.6% in 2022, with some economists predicting a recession.\n",
      "\n",
      "**Key statistics:**\n",
      "\n",
      "* Nominal GDP (in billions of dollars):\n",
      "\t+ 2020: $22.67 trillion\n",
      "\t+ 2021: $23.93 trillion\n",
      "\t+ 2022: $24.83 trillion\n",
      "* Real GDP growth rates:\n",
      "\t+ 2020: -3.4%\n",
      "\t+ 2021: 5.7%\n",
      "\t+ 2022: 1.6%\n",
      "\n",
      "Keep in mind that these numbers are subject to revision and may be updated as more data becomes available.\n",
      "\n",
      "Sources:\n",
      "\n",
      "* Bureau of Economic Analysis (BEA)\n",
      "* Federal Reserve Economic Data (FRED)\n"
     ]
    }
   ],
   "source": [
    "result_without_rag = llm_call(query, use_rag=False, top_k=3)\n",
    "\n",
    "print(result_without_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969e988-3f85-466e-9f42-43458e72e592",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Using Retrieval-Augmented Generation (RAG) in querying a Large Language Model (LLM) significantly improves factual accuracy and contextual relevance compared to not using RAG. Without RAG, the LLM relies solely on its pre-trained knowledge, which can lead to outdated or hallucinated responses when dealing with domain-specific or recent information. In contrast, RAG enhances the process by retrieving relevant documents or chunks from an external knowledge base and feeding them into the model as context, enabling more precise, up-to-date, and source-grounded answers. This makes RAG particularly useful for dynamic domains like news, legal, and enterprise data, whereas relying on an LLM alone limits the model to static knowledge and increases the risk of incomplete or incorrect answers.\n",
    "\n",
    "There are several advanced search techniques that outperform the basic cosine similarity approach typically used with embeddings. While cosine similarity is simple and widely adopted for measuring vector similarity, it does not scale well for very large datasets and lacks semantic refinement. Next blogs will show the usage of other advanced search methods in retriever."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500039f-e0cc-486c-bd64-214ee443bc4a",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "\n",
    "This blog draws inspiration from the RAG course by **deeplearning.ai**. However, instead of using the OpenAI API with Together.ai, as demonstrated in the course, I’ve implemented the solution using **Ollama**, an open-source, quantized model that can even run on your CPU. While responses might take a few seconds depending on your input data, this approach eliminates the need for external APIs.\n",
    "\n",
    "You can check out the original course here: [Retrieval-Augmented Generation (RAG) on Coursera](https://www.coursera.org/learn/retrieval-augmented-generation-rag/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969ca61-4cd2-4c29-8625-cef6f8b35444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env_conda",
   "language": "python",
   "name": "llm_env_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
