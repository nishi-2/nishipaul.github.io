{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4068a3c-1079-4778-9939-c1abf8d237c5",
   "metadata": {},
   "source": [
    "## Crafting Better Prompts for LLMs:\n",
    "\n",
    "In this guide, we’ll explore practical ways to interact with Large Language Models (LLMs) and make your prompts smarter and more effective. Working with LLMs isn’t just about asking questions, it’s about asking them well. The right context and structure can transform a basic query into a highly accurate and relevant response. That’s exactly what we’ll focus on here: **how to enrich your prompts with additional information so the model delivers better, more precise answers**.\n",
    "\n",
    "Here’s what we will do in this blog:\n",
    "\n",
    "* **How to interact with an LLM effectively** - from sending single prompts to managing multi-turn conversations.\n",
    "* **How to enhance your prompts with extra data and context** - so the responses you get are richer, more accurate, and truly useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3894057-46fb-4026-9212-6e3cb952b308",
   "metadata": {},
   "source": [
    "### Setting up some functions to use frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fa8c0d-aaea-4bbd-8eb7-bc0208d59dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a5cdbb-6f24-4733-a624-d3bca8a11f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d2c1dc-59c0-40a5-94e7-f95322117c61",
   "metadata": {},
   "source": [
    "#### `generate_with_single_input` – Your Gateway to Simple LLM Calls\n",
    "\n",
    "The `generate_with_single_input` function is designed to make it easy to generate text from a language model using just **one input prompt**. Think of it as your simplest entry point into interacting with an LLM, perfect for quick experiments or straightforward use cases.\n",
    "\n",
    "For now, we’ll keep things simple and focus on the essential parameters that let you control the model’s behavior without overwhelming complexity.\n",
    "\n",
    "Here’s what you can work with:\n",
    "\n",
    "* **`prompt` (str)**: The actual text you want to send to the model. This is your question, instruction, or context or all of it together.\n",
    "* **`role` (str)**: Defines the role of the message sender (e.g., `\"user\"`, `\"system\"`). Defaults to `\"user\"`.\n",
    "* **`temperature` (float)**: Controls creativity. Lower values (e.g., `0.1`) keep responses focused and deterministic, while higher values make them more diverse.\n",
    "* **`top_p` (float)**: A sampling method to limit randomness by focusing on top probable tokens.\n",
    "* **`max_tokens` (int)**: The maximum length of the response you want from the model.\n",
    "* **`model` (str)**: The LLM you want to use, such as I used `\"llama3.1:8b\"`from Ollama.\n",
    "* **`frequency_penalty` (float)**: Reduces repeated words or phrases in the response, making the output less redundant. Default to 0.5\n",
    "* **`presence_penalty` (float)**: Encourages the model to introduce new ideas and avoid sticking only to what’s already mentioned. Default to 0.3\n",
    "\n",
    "\n",
    "This function keeps the process lightweight and straightforward. Just provide a prompt, tweak a few knobs like `temperature` and `top_p`, and you’re ready to see the model in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3d03f9-f847-4734-abb9-f8f25f96225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_single_input(\n",
    "                            prompt: str,\n",
    "                            role: str = 'user',\n",
    "                            top_p: float = 0.1,\n",
    "                            temperature: float = 0.1,\n",
    "                            max_tokens: int = 500,\n",
    "                            model: str = \"llama3.1:8b\",\n",
    "                            **kwargs\n",
    "                                ):\n",
    "\n",
    "\n",
    "    llm = ChatOllama(\n",
    "        model = model,\n",
    "        temperature = temperature,\n",
    "        top_p= top_p,\n",
    "        frequency_penalty = 0.5,\n",
    "        presence_penalty = 0.3,\n",
    "        max_tokens = max_tokens\n",
    "        )\n",
    "\n",
    "    \n",
    "    role_map = {\"user\" : HumanMessage,\n",
    "                \"system\" : SystemMessage,\n",
    "                \"assistant\" : AIMessage}\n",
    "\n",
    "    # OpenAI Style payload - usually the hyperparameters are placed here if calling for OpenAI API\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": role, \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    content_passed = payload['messages'][0]['content']\n",
    "    role = role_map[payload['messages'][0]['role'].lower()]\n",
    "    messages = [role(content=content_passed)] # Ollama do not accept input in dictionary format or OpenAI style format\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    response_role = \"assistant\" if response.type == \"ai\" else response.type\n",
    "    response_type = {'Role':response_role}\n",
    "\n",
    "    # Convert to dictionary\n",
    "    json_dict = response.model_dump()\n",
    "    json_dict.update(response_type)  # Adding response type with the response dictionary\n",
    "\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2084dde-9fbb-48c1-933f-f603e091884d",
   "metadata": {},
   "source": [
    "#### **`generate_with_multiple_input` – For Multi-Turn Conversations**\n",
    "\n",
    "The `generate_with_multiple_input` function is built to handle **multiple messages in a conversational flow**, making it ideal for scenarios where context from previous exchanges matters.\n",
    "\n",
    "The input follows a simple structure:\n",
    "* **`role`**: Defines who is speaking (`\"user\"`, `\"system\"`, or `\"assistant\"`).\n",
    "* **`content`**: The actual text of the message.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "* **`messages` (List\\[Dict])**: A list of message objects, each containing `role` and `content` to represent the conversation turns.\n",
    "* **`max_tokens` (int)**: Sets the maximum token limit for the model’s response.\n",
    "\n",
    "Other parameters are same as in first function.\n",
    "This function gives you the flexibility to include **system instructions, user queries, and assistant responses**, ensuring the model stays aligned with the ongoing context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5a1bd5-fdc7-48c9-ae2b-2eb70ba59b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_multiple_input(\n",
    "                            messages: List[Dict],\n",
    "                            top_p: float = 0.1,\n",
    "                            temperature: float = 0.1,\n",
    "                            max_tokens: int = 500,\n",
    "                            model: str = \"llama3.1:8b\",\n",
    "                            **kwargs\n",
    "                                ):\n",
    "\n",
    "\n",
    "    llm = ChatOllama(\n",
    "        model = model,\n",
    "        temperature = temperature,\n",
    "        top_p= top_p,\n",
    "        frequency_penalty = 0.5,\n",
    "        presence_penalty = 0.3,\n",
    "        max_tokens = max_tokens\n",
    "        )\n",
    "\n",
    "    \n",
    "    role_map = {\"user\" : HumanMessage,\n",
    "                \"system\" : SystemMessage,\n",
    "                \"assistant\" : AIMessage}\n",
    "\n",
    "\n",
    "    converted_messages = [role_map[m[\"role\"].lower()](content=m[\"content\"]) for m in messages]\n",
    "\n",
    "    response = llm.invoke(converted_messages)\n",
    "    response_role = \"assistant\" if response.type == \"ai\" else response.type\n",
    "\n",
    "    \n",
    "    ## Start - This block is for returning the final result only and not the conversation log\n",
    "    # Convert to dictionary\n",
    "    #json_dict =  {\n",
    "    #    \"role\": response_role,\n",
    "    #    \"content\": response.content\n",
    "    #}\n",
    "    #return json_dict\n",
    "    ## End\n",
    "\n",
    "    # This is for returning the full conversation log passed\n",
    "    conversation_log = [\n",
    "        {\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in messages\n",
    "    ]\n",
    "    conversation_log.append({\"role\": response_role, \"content\": response.content})\n",
    "\n",
    "    return conversation_log\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91f693-8365-4edc-bcde-79360d0dfa91",
   "metadata": {},
   "source": [
    "### Try out the functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c304cd0-d251-47a7-9bc1-f2b731055c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = generate_with_single_input(\n",
    "    prompt = 'What is the capital of India?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0997037-f4bb-4c0b-b031-9ff8cc2ecddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role:  assistant\n",
      "Content:  The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "print('Role: ', output['Role'])\n",
    "print('Content: ', output['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc10fa0e-d9e7-4e59-9571-30e6082d2ac1",
   "metadata": {},
   "source": [
    "Great! Now with multiple turn inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73140e3-e66c-466d-8bd6-b2c4b992d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role':'user', 'content': 'Where is India?'},\n",
    "    {'role':'assistant', 'content':'India is in Asia'},\n",
    "    {'role':'user', 'content':'Who is the Prime Minister?'}\n",
    "]\n",
    "\n",
    "output = generate_with_multiple_input(messages, max_tokens=100, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0926cb-2362-4275-aa7a-355e67303711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Where is India?'},\n",
       " {'role': 'assistant', 'content': 'India is in Asia'},\n",
       " {'role': 'user', 'content': 'Who is the Prime Minister?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"As of my last update (May 2023), Narendra Modi has been serving as the Prime Minister of India since May 2014. However, please note that this information may change over time due to elections or other political developments.\\n\\nIf you're looking for more up-to-date information, I recommend checking a reliable news source or the official website of the Government of India for the latest updates on the current Prime Minister.\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8045c8a-e4ff-4db8-9b0d-35b8984ca3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used when a single output is returned and not conversation log as above\n",
    "#print(\"Role:\", output['role'])\n",
    "#print(\"Content:\", output['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee8e77-4834-4e13-a837-8f827d5dfc16",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Introducing Augmenting\n",
    "\n",
    "Now we will learn how to incorporate data into a prompt before passing it to a LLM.\n",
    "We will use a small dataset of JSON files containing information about houses. This example will help you understand how to augment prompts in the context of Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "The dataset is simple: a list where each element represents a house as a dictionary of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ccac92-b11d-49d6-a232-da4618bb3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data = [\n",
    "    {\n",
    "        \"address\": \"123 Maple Street\",\n",
    "        \"city\": \"Springfield\",\n",
    "        \"state\": \"IL\",\n",
    "        \"zip\": \"62701\",\n",
    "        \"bedrooms\": 3,\n",
    "        \"bathrooms\": 2,\n",
    "        \"square_feet\": 1500,\n",
    "        \"price\": 230000,\n",
    "        \"year_built\": 1998\n",
    "    },\n",
    "    {\n",
    "        \"address\": \"456 Elm Avenue\",\n",
    "        \"city\": \"Shelbyville\",\n",
    "        \"state\": \"TN\",\n",
    "        \"zip\": \"37160\",\n",
    "        \"bedrooms\": 4,\n",
    "        \"bathrooms\": 3,\n",
    "        \"square_feet\": 2500,\n",
    "        \"price\": 320000,\n",
    "        \"year_built\": 2005\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd2129-4271-4c1d-942f-f0efe79d9454",
   "metadata": {},
   "source": [
    "**Let's begin by constructing the prompt. The first step is to design a layout for the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37dfc042-df64-4e28-b1e6-e83b27b003a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def house_info_layout(houses):\n",
    "    layout = ''\n",
    "\n",
    "    for house in houses:\n",
    "        layout += (\n",
    "            f\"House located at {house['address']}, {house['city']}, {house['state']} {house['zip']} with \"\n",
    "            f\"{house['bedrooms']} bedrooms, {house['bathrooms']} bathrooms, \"\n",
    "            f\"{house['square_feet']} sq feet area, priced at ${house['price']}, \"\n",
    "            f\"built in {house['year_built']}.\\n\"\n",
    "        )\n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421fd1af-7418-4656-bb7f-4f92d33aef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House located at 123 Maple Street, Springfield, IL 62701 with 3 bedrooms, 2 bathrooms, 1500 sq feet area, priced at $230000, built in 1998.\n",
      "House located at 456 Elm Avenue, Shelbyville, TN 37160 with 4 bedrooms, 3 bathrooms, 2500 sq feet area, priced at $320000, built in 2005.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(house_info_layout(house_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41faef-3107-4d6a-a698-071e421dfa83",
   "metadata": {},
   "source": [
    "**Now create a function that generates the prompt to be passed to the Language Learning Model (LLM). The function will take a user-provided query and the available housing data as inputs to effectively address the user's query.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5259c940-8ed4-4f1a-8fe7-82b5f81c7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(query, house):\n",
    "    house_layout = house_info_layout(house)\n",
    "    PROMPT = f\"\"\"\n",
    "    Use the following houses information to answer the user queries.\n",
    "    {house_layout}\n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    "    return PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3389e24e-5758-4c08-81a6-44bfc331c0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Use the following houses information to answer the user queries.\n",
      "    House located at 123 Maple Street, Springfield, IL 62701 with 3 bedrooms, 2 bathrooms, 1500 sq feet area, priced at $230000, built in 1998.\n",
      "House located at 456 Elm Avenue, Shelbyville, TN 37160 with 4 bedrooms, 3 bathrooms, 2500 sq feet area, priced at $320000, built in 2005.\n",
      "\n",
      "    Query: What is the most expensive house?\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt(\"What is the most expensive house?\", house = house_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ddeaee-148f-4f20-9fc0-8640a79571a6",
   "metadata": {},
   "source": [
    "**Now make the call to the model without passing the housing data and observe the output -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633efe92-6ca0-4a4f-801d-bf04cc589c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'The title of \"most expensive house\" can be subjective and may vary depending on various factors such as location, size, amenities, and market conditions. However, here are some of the most expensive houses in the world:\\n\\n1. **Antilia**, Mumbai, India - Estimated value: $1 billion (approximately ₹7,500 crore)\\n\\t* Owned by business magnate Mukesh Ambani, Antilia is a 27-story skyscraper that serves as his private residence.\\n2. **The One**, Bel Air, California, USA - Estimated value: $500 million\\n\\t* This mega-mansion was designed by Paul McClean and features 20 bedrooms, 30 bathrooms, and over 105,000 square feet of living space.\\n3. **Villa Leopolda**, Villefranche-sur-Mer, France - Sold for: €750 million (approximately $850 million)\\n\\t* This luxurious villa is situated on the French Riviera and boasts stunning views of the Mediterranean Sea.\\n4. **The Biltmore Estate**, Asheville, North Carolina, USA - Estimated value: $400-500 million\\n\\t* This grand chateau-style mansion was built by George Vanderbilt in 1895 and features over 250 rooms, including 35 bedrooms and 43 bathrooms.\\n5. **Xanadu 2.0**, Medina, Washington, USA - Sold for: $165 million (approximately ₹1,200 crore)\\n\\t* This futuristic estate was designed by Paul Allen, co-founder of Microsoft, and features a private beach, a movie theater, and a collection of rare art pieces.\\n6. **The Four Winds Estate**, Bel Air, California, USA - Estimated value: $250-300 million\\n\\t* This luxurious estate boasts 12 bedrooms, 15 bathrooms, and over 29,000 square feet of living space.\\n7. **Elvis Presley\\'s Graceland**, Memphis, Tennessee, USA - Sold for: $100 million (approximately ₹750 crore)\\n\\t* The former home of the King of Rock \\'n\\' Roll is a National Historic Landmark and features a stunning mansion with over 23 rooms.\\n\\nPlease note that these estimates may vary depending on various factors such as market conditions, location, and other considerations.',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'model': 'llama3.1:8b',\n",
       "  'created_at': '2025-08-16T06:54:32.0845949Z',\n",
       "  'done': True,\n",
       "  'done_reason': 'stop',\n",
       "  'total_duration': 52381344900,\n",
       "  'load_duration': 40895700,\n",
       "  'prompt_eval_count': 17,\n",
       "  'prompt_eval_duration': 518189500,\n",
       "  'eval_count': 459,\n",
       "  'eval_duration': 51821655300,\n",
       "  'model_name': 'llama3.1:8b'},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run--7741a5b0-013f-4c1d-8621-83e022045cb4-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 17,\n",
       "  'output_tokens': 459,\n",
       "  'total_tokens': 476},\n",
       " 'Role': 'assistant'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the most expensive house?\"\n",
    "\n",
    "query_without_house_info = generate_with_single_input(prompt = query, role = 'user')\n",
    "\n",
    "query_without_house_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d6676f5-1843-4d48-a6e6-54d4bd7f621a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of \"most expensive house\" can be subjective and may vary depending on various factors such as location, size, amenities, and market conditions. However, here are some of the most expensive houses in the world:\n",
      "\n",
      "1. **Antilia**, Mumbai, India - Estimated value: $1 billion (approximately ₹7,500 crore)\n",
      "\t* Owned by business magnate Mukesh Ambani, Antilia is a 27-story skyscraper that serves as his private residence.\n",
      "2. **The One**, Bel Air, California, USA - Estimated value: $500 million\n",
      "\t* This mega-mansion was designed by Paul McClean and features 20 bedrooms, 30 bathrooms, and over 105,000 square feet of living space.\n",
      "3. **Villa Leopolda**, Villefranche-sur-Mer, France - Sold for: €750 million (approximately $850 million)\n",
      "\t* This luxurious villa is situated on the French Riviera and boasts stunning views of the Mediterranean Sea.\n",
      "4. **The Biltmore Estate**, Asheville, North Carolina, USA - Estimated value: $400-500 million\n",
      "\t* This grand chateau-style mansion was built by George Vanderbilt in 1895 and features over 250 rooms, including 35 bedrooms and 43 bathrooms.\n",
      "5. **Xanadu 2.0**, Medina, Washington, USA - Sold for: $165 million (approximately ₹1,200 crore)\n",
      "\t* This futuristic estate was designed by Paul Allen, co-founder of Microsoft, and features a private beach, a movie theater, and a collection of rare art pieces.\n",
      "6. **The Four Winds Estate**, Bel Air, California, USA - Estimated value: $250-300 million\n",
      "\t* This luxurious estate boasts 12 bedrooms, 15 bathrooms, and over 29,000 square feet of living space.\n",
      "7. **Elvis Presley's Graceland**, Memphis, Tennessee, USA - Sold for: $100 million (approximately ₹750 crore)\n",
      "\t* The former home of the King of Rock 'n' Roll is a National Historic Landmark and features a stunning mansion with over 23 rooms.\n",
      "\n",
      "Please note that these estimates may vary depending on various factors such as market conditions, location, and other considerations.\n"
     ]
    }
   ],
   "source": [
    "print(query_without_house_info['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb4983-3498-460a-b4d5-3c5d6eefcd28",
   "metadata": {},
   "source": [
    "**Now make the query by passing the housing data and observe the output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43892693-cb25-484a-899b-0cd20c4ae6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the most expensive house?\"\n",
    "\n",
    "enhanced_query = generate_prompt(query, house=house_data)\n",
    "query_with_house_info = generate_with_single_input(prompt = enhanced_query, role='assistant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29caa9a8-e827-4cb5-a177-9df3b5deb7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - The most expensive house is the one located at 456 Elm Avenue, Shelbyville, TN 37160.\n"
     ]
    }
   ],
   "source": [
    "print(query_with_house_info['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a018b79-b02e-4e47-9077-40fe8dff9aa7",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572c587-a3d4-4d61-a210-0efc962f5e75",
   "metadata": {},
   "source": [
    "Augmenting data with prompts involves enriching the input provided to a LLM by including relevant context, facts, or structured data before sending it for inference. Instead of relying solely on the LLM's pre-trained knowledge, you supply domain-specific details—such as product specs, financial figures, or a subset of a dataset—directly in the prompt.\n",
    "\n",
    "This approach is critical in **Retrieval-Augmented Generation (RAG)** systems, where data from external sources (e.g., JSON, databases, vector stores) is retrieved and embedded into the prompt. By doing so:\n",
    "\n",
    "* **Accuracy Improves**: The model has access to the exact, up-to-date information instead of hallucinating or giving generic responses.\n",
    "* **Computation Is Faster**: Since the model does not need to reason broadly or infer missing details, the search space for generating answers is reduced, leading to quicker response times and lower token usage.\n",
    "\n",
    "In short, prompt augmentation creates a balance between LLM general intelligence and real-time factual accuracy while improving efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df91a77b-b9e3-4fe8-94c7-a77bb549f33a",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "\n",
    "This blog draws inspiration from the RAG course by **deeplearning.ai**. However, instead of using the OpenAI API with Together.ai, as demonstrated in the course, I’ve implemented the solution using **Ollama**, an open-source, quantized model that can even run on your CPU. While responses might take a few seconds depending on your input data, this approach eliminates the need for external APIs.\n",
    "\n",
    "You can check out the original course here: [Retrieval-Augmented Generation (RAG) on Coursera](https://www.coursera.org/learn/retrieval-augmented-generation-rag/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d199efb-2ce8-4601-9202-97970a628714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env_conda",
   "language": "python",
   "name": "llm_env_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
